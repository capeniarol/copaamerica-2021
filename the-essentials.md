---
layout: default
title: "The essentials"
author: "Eldorado Sportmedia"
name: "the-essentials.md"
---

<h2>The essentials</h2>
<hr>

<h4>Web crawler</h4>
<hr>

<p>A web crawler (also known as a web spider or web robot) is a program or automated script which browses the World Wide Web in a methodical, automated manner.</p>

<p>Web crawlers are mainly used to create a copy of all the visited pages for later processing by a search engine, that will index the downloaded pages to provide fast searches.</p>

<p>Crawlers can also be used for automating maintenance tasks on a Web site, such as checking links or validating HTML code.</p>

<p>Also, crawlers can be used to gather specific types of information from Web pages, such as harvesting e-mail addresses (usually for spam).</p>

<p><strong>Note: </strong>The above text is excerpted from the Wikipedia article <a href="http://en.wikipedia.org/wiki/Web_crawler">"Web crawler"</a>, which has been released under the <a href="http://www.gnu.org/copyleft/fdl.html">GNU Free Documentation License</a>.</p>
